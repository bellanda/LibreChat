# For more information, see the Configuration Guide:
# https://www.librechat.ai/docs/configuration/librechat_yaml

# Configuration version (required)
version: 1.2.1

# Cache settings: Set to true to enable caching
cache: true

# File strategy s3/firebase
# fileStrategy: "s3"

# Custom interface configuration
interface:
  customWelcome: 'Bem vindos √† plataforma HPE-IA üß†'
  # Privacy policy settings
  privacyPolicy:
    externalUrl: 'https://ia.hpeautos.com.br/documentation/politica-de-uso-de-ia'
    openNewTab: true

  # Terms of service
  termsOfService:
    externalUrl: 'https://ia.hpeautos.com.br/documentation/politica-de-uso-de-ia'
    openNewTab: true
    modalAcceptance: true
    modalTitle: 'Pol√≠tica de Uso de IA para HPE IA Core'
    modalContent: |
      **ATUALIZA√á√ÉO!!!**

      *31/10/2025*

      # üìú **Pol√≠tica Interna de Uso de Intelig√™ncia Artificial**  

      ## üìÑ **Documenta√ß√£o**  

      | üìÑ **C√≥digo** | üìë **Revis√£o** | üóÇÔ∏è **Categoria** |
      |---------------|----------------|-------------------|
      | **POL‚ÄëCORP‚ÄëCOMPL‚Äë0005** | **01** | **POL√çTICA** |

      ---  

      ## üìë **Sum√°rio**  

      | # | Se√ß√£o | üìÑ P√°gina |
      |---|-------|-----------|
      | 1Ô∏è‚É£ | üéØ **Objetivo** | 2 |
      | 2Ô∏è‚É£ | üåç **Abrang√™ncia** | 2 |
      | 3Ô∏è‚É£ | üìö **Defini√ß√µes** | 2 |
      | 4Ô∏è‚É£ | ü§ñ **Intelig√™ncia Artificial** | 3 |
      | 5Ô∏è‚É£ | ‚öñÔ∏è **Princ√≠pios Orientadores do Uso √âtico de Ferramentas de IA** | 3 |
      | 6Ô∏è‚É£ | üë• **Comit√™ de IA** | 4 |
      | 7Ô∏è‚É£ | üîß **Plataformas de IA Autorizadas para Uso** | 4 |
      | 7.1 |‚ÄÉüõ†Ô∏è **HPE‚ÄëIA** | 4 |
      | 7.2 |‚ÄÉüõ†Ô∏è **Outras Plataformas Homologadas** | 4 |
      | 8Ô∏è‚É£ | üõ†Ô∏è **Diretrizes de Uso** | 5 |
      | 8.1 |‚ÄÉ‚úÖ **Responsabilidade dos Usu√°rios** | 6 |
      | 9Ô∏è‚É£ | üîê **Seguran√ßa da Informa√ß√£o** | 6 |
      | üîü | üíæ **Armazenamento e Reten√ß√£o de Dados** | 6 |
      | 1Ô∏è‚É£1Ô∏è‚É£ | üìà **Monitoramento, Auditoria e Penalidades** | 7 |
      | 1Ô∏è‚É£2Ô∏è‚É£ | üìñ **Refer√™ncias** | 7 |
      | 1Ô∏è‚É£3Ô∏è‚É£ | üîÑ **Atualiza√ß√µes** | 7 |
      | 1Ô∏è‚É£4Ô∏è‚É£ | üìÇ **Controle do Documento** | 7 |
      | 1Ô∏è‚É£5Ô∏è‚É£ | üìã **N√≠veis de Aprova√ß√£o** | 7 |

      ---  

      ## üéØ 1. **Objetivo**  

      Esta pol√≠tica (**‚ÄúPol√≠tica de IA‚Äù**) tem como objetivo estabelecer diretrizes claras e abrangentes para o uso **seguro, transparente e respons√°vel** de ferramentas de Intelig√™ncia Artificial no √¢mbito organizacional.

      - O uso respons√°vel da IA permite ganhos significativos em **produtividade, criatividade** e **suporte √† tomada de decis√£o**, atuando como ferramenta estrat√©gica de apoio aos processos internos.  
      - Esse uso dever√° estar sempre alinhado aos **valores da HPE** ‚Äì conforme constam no nosso **C√≥digo de √âtica e Conduta dos Colaboradores** ‚Äì ou seja, em estrita conformidade com os princ√≠pios √©ticos e demais pol√≠ticas internas.  

      ---  

      ## üåç 2. **Abrang√™ncia**  

      Esta pol√≠tica se aplica a **todos os colaboradores da HPE Automotores do Brasil Ltda. (‚ÄúHPE‚Äù)** e das demais empresas do Grupo. Tamb√©m se estende, quando aplic√°vel, a **terceiros, prestadores de servi√ßo e parceiros** que utilizem, direta ou indiretamente, as ferramentas de IA fornecidas ou autorizadas pela HPE, identificados nesta pol√≠tica como **‚ÄúUsu√°rios‚Äù**.  

      ---  

      ## üìö 3. **Defini√ß√µes**  

      | **Termo** | **Defini√ß√£o** |
      |-----------|---------------|
      | **Agentes de IA** | Programas ou sistemas que utilizam Intelig√™ncia Artificial para executar atividades de forma aut√¥noma ou semiaut√¥noma. Podem interagir com pessoas, outros sistemas ou at√© com outros agentes de IA (ex.: chatbots, assistentes virtuais, softwares de monitoramento autom√°tico). |
      | **Agentes Aut√¥nomos** | Modelos de IA que podem realizar tarefas complexas sem supervis√£o humana constante, aprendendo com o ambiente e tomando decis√µes baseadas em seus objetivos. |
      | **Algoritmos** | Conjuntos de instru√ß√µes l√≥gicas e matem√°ticas que orientam como um dispositivo ou sistema deve processar informa√ß√µes para alcan√ßar determinado resultado. |
      | **Alucina√ß√µes** | Gera√ß√£o de conte√∫do **falso, incoerente ou inventado** por um modelo de IA, ainda que pare√ßa plaus√≠vel. Ocorrem quando o modelo ‚Äúpreenche lacunas‚Äù de conhecimento com padr√µes aprendidos, n√£o baseados em dados reais. |
      | **Ataques Cibern√©ticos** | A√ß√µes maliciosas realizadas por indiv√≠duos ou grupos com o objetivo de comprometer sistemas, redes ou dados (ex.: roubo de informa√ß√µes, interrup√ß√£o de servi√ßos, fraude, espionagem). |
      | **Backup** | C√≥pia de seguran√ßa das informa√ß√µes, realizada para evitar perdas em caso de falhas t√©cnicas, exclus√£o acidental, ataques cibern√©ticos ou desastres. |
      | **Criptografia** | T√©cnica de prote√ß√£o que transforma informa√ß√µes em um c√≥digo indecifr√°vel para quem n√£o possui a chave correta de leitura. |
      | **Dados Pessoais** | Informa√ß√µes que identificam ou permitem identificar uma pessoa, direta ou indiretamente (nome, CPF, RG, e‚Äëmail, telefone, endere√ßo, geolocaliza√ß√£o, identificadores digitais etc.). |
      | **IA Generativa** | Tipo de IA projetada para desenvolver conte√∫do a partir de grandes volumes de dados j√° existentes (texto, imagens, m√∫sicas, v√≠deos, c√≥digo). |
      | **Identificadores Digitais** | Informa√ß√µes eletr√¥nicas que permitem reconhecer ou diferenciar um usu√°rio, dispositivo ou conex√£o na internet. |
      | **Incidentes de Seguran√ßa** | Eventos que afetam a **confidencialidade, integridade ou disponibilidade** de informa√ß√µes e sistemas. |
      | **Modelos de IA** | Estruturas matem√°ticas e computacionais treinadas com grandes volumes de dados para reconhecer padr√µes, tomar decis√µes ou gerar resultados de forma autom√°tica. |
      | **Prompt** | Comando, pergunta ou instru√ß√£o fornecida a um sistema de IA para direcionar sua resposta ou a√ß√£o. Quanto mais claro e detalhado for o prompt, maior a chance de gerar um resultado √∫til e adequado. |

      ---  

      ## ü§ñ 4. **Intelig√™ncia Artificial**  

      Intelig√™ncia Artificial (**IA**) √© um ramo da ci√™ncia da computa√ß√£o voltado ao desenvolvimento de sistemas capazes de executar tarefas que tradicionalmente requerem a **intelig√™ncia humana**, tais como racioc√≠nio, aprendizado, percep√ß√£o e tomada de decis√£o.

      No contexto corporativo, a IA generativa pode ser utilizada para diversas finalidades, como, por exemplo:

      - Apoio √† reda√ß√£o de documentos;  
      - Elabora√ß√£o de relat√≥rios;  
      - Cria√ß√£o de apresenta√ß√µes;  
      - Personaliza√ß√£o de campanhas de marketing;  
      - Automa√ß√£o de atendimento ao cliente;  
      - Gera√ß√£o de insights estrat√©gicos a partir de padr√µes aprendidos em grandes volumes de dados.  

      ---  

      ## ‚öñÔ∏è 5. **Princ√≠pios Orientadores do Uso √âtico de Ferramentas de IA**  

      O uso da IA dever√° estar sempre alinhado aos seguintes princ√≠pios orientadores:

      - **Diversidade, Equidade e N√£o Discrimina√ß√£o** ‚Äì garantir que os resultados n√£o reforcem preconceitos ou discrimina√ß√µes contra indiv√≠duos ou grupos, respeitando dignidade, igualdade e diversidade.  
      - **Melhoria Cont√≠nua** ‚Äì garantir que os sistemas de IA sejam revisados e aprimorados regularmente, ajustando‚Äëos √†s novas necessidades de neg√≥cio e aos desafios √©ticos/tecnol√≥gicos.  
      - **Privacidade e Governan√ßa dos Dados** ‚Äì garantir que os dados pessoais sejam tratados com respeito √† privacidade dos indiv√≠duos, em conformidade com a legisla√ß√£o de prote√ß√£o de dados.  
      - **Responsabilidade** ‚Äì garantir supervis√£o humana adequada em toda decis√£o relevante, especialmente aquelas que possam impactar pessoas, processos ou resultados cr√≠ticos.  
      - **Seguran√ßa e Confiabilidade** ‚Äì proteger dados sens√≠veis e sigilosos, evitando a exposi√ß√£o de informa√ß√µes pessoais de clientes e colaboradores; utilizar IA apenas em dispositivos e redes corporativas seguras e homologadas.  
      - **Transpar√™ncia** ‚Äì garantir defini√ß√£o clara dos modelos utilizados e a finalidade de sua utiliza√ß√£o, assegurando rastreabilidade, documenta√ß√£o e atribui√ß√£o clara de responsabilidade ao longo de todo o ciclo de uso da IA.  

      ---  

      ## üë• 6. **Comit√™ de IA**  

      O **Comit√™ de Intelig√™ncia Artificial** ser√° respons√°vel por coordenar e supervisionar o uso das tecnologias de IA na organiza√ß√£o, assegurando que sua aplica√ß√£o esteja alinhada aos princ√≠pios √©ticos, √† prote√ß√£o de dados pessoais, √†s exig√™ncias legais e √†s diretrizes estrat√©gicas da empresa.

      ### üë• **Composi√ß√£o**  
      - **Compliance e Privacidade de Dados**  
      - **Tecnologia da Informa√ß√£o**  
      - **Gente & Gest√£o**  
      - **Gest√£o de Riscos** (quando necess√°rio)

      ### üìå **Atribui√ß√µes**  

      1. **Orientar e treinar** os colaboradores no uso de IA, promovendo conscientiza√ß√£o sobre riscos, responsabilidades e limita√ß√µes.  
      2. **Definir crit√©rios de homologa√ß√£o** para plataformas de IA autorizadas, avaliando riscos t√©cnicos e regulat√≥rios.  
      3. **Validar o ambiente de uso** das ferramentas de IA (infraestrutura segura, controle de acesso, criptografia, backup, etc.).  
      4. **Monitorar o uso** das ferramentas de IA, assegurando rastreabilidade, preven√ß√£o de incidentes e conformidade com os controles estabelecidos.  
      5. **Avaliar impactos** em seguran√ßa e privacidade decorrentes da ado√ß√£o da IA em projetos, produtos, processos ou iniciativas estrat√©gicas.  

      ---  

      ## üîß 7. **Plataformas de IA Autorizadas para Uso**  

      Os colaboradores da HPE devem utilizar **exclusivamente** as plataformas e sistemas oficialmente autorizados nesta pol√≠tica. √â **expressamente proibido** utilizar modelos de IA que n√£o sejam a **HPE‚ÄëIA** ou que n√£o estejam homologados.

      ### üõ†Ô∏è 7.1 **HPE‚ÄëIA**  

      Este √© o modelo oficial para uso de IA generativa da HPE, criado como solu√ß√£o interna. A plataforma disponibiliza acesso a diversos modelos de IA de alto n√≠vel encontrados no mercado (ex.: ChatGPT, Gemini, etc.), todos integrados em um ambiente seguro e f√°cil de usar, garantindo maior seguran√ßa e integridade na governan√ßa dos dados corporativos, al√©m de alta capacidade de auditoria e transpar√™ncia.  

      ### üõ†Ô∏è 7.2 **Outras Plataformas Homologadas**  

      Caso surja necessidade de utiliza√ß√£o de outras plataformas e sistemas que n√£o sejam a HPE‚ÄëIA, devem ser analisados os seguintes crit√©rios:

      - **Crit√©rio 1** ‚Äì O sistema utiliza IA em sua totalidade e n√£o pode ser contemplado na plataforma HPE‚ÄëIA.  
      - **Crit√©rio 2** ‚Äì O sistema n√£o utiliza IA em sua totalidade, mas possui recursos de IA significativos.  
      - **Crit√©rio 3** ‚Äì O fornecedor da HPE n√£o foi contratado originalmente para fornecer produtos ou servi√ßos que utilizam IA.

      #### üìÑ **Requerimento de Homologa√ß√£o**  

      O requerimento deve ser enviado para **ia.comite@hpeautos.com.br** contendo, de forma detalhada:

      1. **Aprova√ß√£o pr√©via** do gestor (quando aplic√°vel).  
      2. **Finalidade do uso** da plataforma ou sistema.  
      3. **Detalhamento dos dados** que ser√£o utilizados:  
        - (i) Dados pessoais (sens√≠veis ou n√£o) ‚Äì ex.: e‚Äëmail, nome, CPF, etc.;  
        - (ii) Informa√ß√µes da empresa (confidenciais ou n√£o) ‚Äì ex.: tabelas, manuais, relat√≥rios, contratos, planilhas;  
        - (iii) Tipo de modelo de treinamento ou agente aut√¥nomo;  
        - (iv) Tempo de utiliza√ß√£o (tempor√°ria ou permanente);  
        - (v) Colaboradores que ter√£o acesso √† ferramenta.  

      #### ‚è±Ô∏è **SLA de Homologa√ß√£o**  

      - **15 (quinze) dias √∫teis** para plataformas que **n√£o** necessitem de testes de uso;  
      - **30 (trinta) dias √∫teis** para plataformas que **exijam** testes de uso.  

      > **Importante:** O uso de plataformas n√£o homologadas √© **vedado** e pode ser configurado como atitude anti√©tica, nos termos do item 7.2.9 do C√≥digo de √âtica e Conduta da HPE, sujeitando o respons√°vel a medidas disciplinares.  

      ---  

      ## üõ†Ô∏è 8. **Diretrizes de Uso**  

      O uso da plataforma **HPE‚ÄëIA** e demais sistemas homologados deve estar em conformidade com o **C√≥digo de √âtica e Conduta dos Colaboradores**, a **Pol√≠tica de Privacidade e Prote√ß√£o de Dados Pessoais**, a **Pol√≠tica de Seguran√ßa da Informa√ß√£o**, bem como demais pol√≠ticas internas da HPE.

      ### ‚úÖ **√â permitido utilizar a IA para:**  

      - Apoiar a cria√ß√£o de conte√∫dos (e‚Äëmails, relat√≥rios, apresenta√ß√µes, documentos t√©cnicos etc.).  
      - Otimizar tarefas administrativas, revis√£o textual, tradu√ß√µes e an√°lise de dados.  
      - Explorar solu√ß√µes e conceitos inovadores relacionados ao setor automotivo.  
      - Desenvolver ideias e realizar simula√ß√µes a fim de obter melhorias em processos.  
      - Apoiar capacita√ß√£o interna, mediante uso da IA para simula√ß√£o de cen√°rios e aprendizado.  
      - Auxiliar na tomada de decis√µes, **desde que** haja valida√ß√£o humana e supervis√£o t√©cnica apropriada.  

      ### ‚ùå **√â expressamente proibido:**  

      - Utilizar IA que viole leis de direitos autorais ou a Lei da Propriedade Industrial (Lei n¬∫‚ÄØ9.279/1996).  
      - Tomar decis√µes automatizadas com impacto financeiro, jur√≠dico, regulat√≥rio ou operacional **sem** revis√£o humana.  

      ---  

      ## ‚úÖ 8.1 **Responsabilidade dos Usu√°rios**  

      O uso de ferramentas de IA generativa exige que o usu√°rio atue com responsabilidade e integridade. Cabe ao usu√°rio interpretar criticamente as informa√ß√µes geradas, revisar seu conte√∫do e garantir sua precis√£o, relev√¢ncia e conformidade com as diretrizes institucionais.

      - **Explicar e justificar** qualquer resultado impreciso, validando criticamente o conte√∫do antes de utiliz√°‚Äëlo, mitigando ‚Äúalucina√ß√µes‚Äù.  
      - **Validar criticamente** o conte√∫do gerado antes de utiliz√°‚Äëlo.  
      - **Revisar o conte√∫do** para garantir que n√£o contenha elementos discriminat√≥rios (ra√ßa, cor, religi√£o, sexo, nacionalidade, idade, defici√™ncia, estado civil, filia√ß√£o pol√≠tica, orienta√ß√£o sexual ou qualquer forma de discrimina√ß√£o vedada por lei).  
      - **Reportar** incidentes de seguran√ßa, d√∫vidas, usos indevidos ou vazamento de informa√ß√µes √† √°rea de Seguran√ßa da Informa√ß√£o **imediatamente** via **incidentes@hpeautos.com.br**.  

      ---  

      ## üîê 9. **Seguran√ßa da Informa√ß√£o**  

      A √°rea de **Seguran√ßa da Informa√ß√£o** da HPE atuar√° na prote√ß√£o dos sistemas e dados corporativos, al√©m de gerenciar incidentes de seguran√ßa da informa√ß√£o e garantir controles adequados para a ciberseguran√ßa.  

      ---  

      ## üíæ 10. **Armazenamento e Reten√ß√£o de Dados**  

      Com o objetivo de garantir a seguran√ßa da informa√ß√£o, a privacidade e a conformidade com legisla√ß√µes aplic√°veis, todas as intera√ß√µes realizadas com as ferramentas de Intelig√™ncia Artificial generativa, por meio dos sistemas homologados pelo Comit√™ de IA, estar√£o sujeitas √†s seguintes diretrizes de **temporalidade e reten√ß√£o de dados**:

      - **Reten√ß√£o de Dados** ‚Äì As informa√ß√µes inseridas e geradas durante o uso das plataformas de IA ser√£o armazenadas **temporariamente**, apenas pelo tempo estritamente necess√°rio para cumprir a finalidade da intera√ß√£o.  
      - **Prazo de Reten√ß√£o** ‚Äì O prazo pode variar conforme a arquitetura, configura√ß√£o e pol√≠tica de armazenamento adotada por cada modelo ou sistema. Quando poss√≠vel, a HPE adotar√° medidas para limitar a reten√ß√£o ao m√≠nimo necess√°rio, promovendo a elimina√ß√£o autom√°tica dos registros ap√≥s seu uso.  
      - **Exce√ß√µes e Auditoria** ‚Äì Em casos de auditoria, an√°lise de seguran√ßa ou investiga√ß√£o formal, os dados poder√£o ser preservados por per√≠odo superior, conforme determina√ß√£o legal ou regulat√≥ria, sempre mediante **autoriza√ß√£o expressa** das diretorias envolvidas no Comit√™ de IA.  

      ---  

      ## üìà 11. **Monitoramento, Auditoria e Penalidades**  

      A HPE poder√° **monitorar** o uso das ferramentas de IA com fins de auditoria, seguran√ßa e conformidade com normas e pol√≠ticas internas.  

      > **San√ß√µes**  
      > Viola√ß√£o desta pol√≠tica pode acarretar **advert√™ncias, suspens√£o do contrato de trabalho, demiss√£o** (com ou sem justa causa) e/ou responsabiliza√ß√£o **civil, administrativa e/ou criminal**, conforme a gravidade do caso.  

      ---  

      ## üìñ 12. **Refer√™ncias**  

      - ISO/IEC‚ÄØ27001:2022 ‚Äì Sistema de Gest√£o de Seguran√ßa da Informa√ß√£o  
      - ISO/IEC‚ÄØ42001:2023 ‚Äì Sistema de Gest√£o de IA  
      - Lei Geral de Prote√ß√£o de Dados (LGPD ‚Äì Lei n¬∫‚ÄØ13.709/2018)  
      - Regulamento (EU)‚ÄØ224/1689, (‚ÄúIA‚ÄØAct‚Äù), de 13‚ÄØde‚ÄØjunho‚ÄØ2024  

      ---  

      ## üîÑ 13. **Atualiza√ß√µes**  

      Esta pol√≠tica poder√° ser **atualizada** sempre que houver mudan√ßas em regulamenta√ß√µes, avan√ßos tecnol√≥gicos ou altera√ß√µes nas necessidades e diretrizes da organiza√ß√£o.  

      ---  

      ## üìÇ 14. **Controle do Documento**  

      | üìÑ **Revis√£o** | üìÖ **Data de Publica√ß√£o** | üõ†Ô∏è **Altera√ß√µes** |
      |----------------|---------------------------|-------------------|
      | 00 | 16/09/2025 | Publica√ß√£o |
      | 01 | 06/10/2025 | Atualiza√ß√£o |

      ---  

      ## üìã 15. **N√≠veis de Aprova√ß√£o**  

      | üè∑Ô∏è **N√≠vel de Aprova√ß√£o** | üë§ **Nome** | üìÇ **√Årea / Fun√ß√£o** |
      |----------------------------|-------------|----------------------|
      | **Elaborador(es)** | Camila Reis Ferreira | Compliance e Privacidade de Dados |
      |  | Everton da Silva Barbosa | Compliance e Privacidade de Dados |
      |  | Janaina Selvino G. Siqueira | Compliance e Privacidade de Dados |
      |  | Jo√£o Emmanuel L. de Oliveira | Compliance e Privacidade de Dados |
      |  | Gustavo Casadei Bellanda | Tecnologia e Inova√ß√£o |
      |  | Victor Hugo Silvino C. da Silva | Tecnologia e Inova√ß√£o |
      | **Aprovador(es)** | Ailton Coimbra Bonfim | Jur√≠dico |
      |  | Eduardo Mauricio Zalamena | Tecnologia e Inova√ß√£o |
      |  | Felipe Frota. de A. Koury | Jur√≠dico |
      |  | Let√≠cia Gon√ßalves Borges | Gente & Gest√£o |
      |  | Mauro Lu√≠s Correia | Presid√™ncia |
      |  | Naasson Carlos de Almeida | Gente & Gest√£o |
      | **Homologadora** | Fabiola Fernandes Barbosa | Sistema de Gest√£o Lean |

      ---  

      *Esta pol√≠tica entra em vigor a partir da data de sua publica√ß√£o e dever√° ser divulgada a todos os usu√°rios e partes interessadas.*

  endpointsMenu: true
  modelSelect: true
  # Lista plana de modelos (sem agrupar por provedor). Use true para agrupar por OpenAI, Google, etc.
  groupModelsByEndpoint: false
  parameters: true
  sidePanel: true
  presets: true
  prompts: true
  bookmarks: true
  multiConvo: true
  peoplePicker:
    users: true
    groups: true
    roles: true
  marketplace:
    use: true
  fileCitations: true

# Example Balance settings
balance:
  enabled: true
  startBalance: 1000000
  autoRefillEnabled: false
  refillIntervalValue: 1
  refillIntervalUnit: 'days'
  refillAmount: 20000

# Example Actions Object Structure
actions:
  allowedDomains:
    - 'http://localhost:3080'
    - 'https://ia.hpeautos.com.br'
    - 'http://ascatorg115:8080'
    - 'http://host.docker.internal:8000'
    - 'http://host.docker.internal:15785'
    - 'https://brasilapi.com.br'
    - 'https://hpeautos.my.salesforce.com'
    - 'swapi.dev'
    - 'librechat.ai'
    - 'google.com'
    - 'https://wscoredev.mmcb.com.br'
    - 'https://wscore.mmcb.com.br'
    - 'https://dpo.privacytools.com.br'

# mcpServers:
#   ask_polars:
#     command: npx
#     args:
#       - mcp-remote
#       - 'https://mcp.polars.workers.dev/sse'

fileConfig:
  # Global file size limit
  serverFileSizeLimit: 256 # 256MB maximum per file

  # Avatar specific
  avatarSizeLimit: 2 # 2MB for avatars

  endpoints:
    assistants:
      fileLimit: 5 # Maximum 5 files per upload
      fileSizeLimit: 256 # Each file up to 256MB
      totalSizeLimit: 512 # Total maximum 512MB per upload

    default:
      fileLimit: 5 # Maximum 5 files per upload
      fileSizeLimit: 256 # Each file up to 256MB
      totalSizeLimit: 512 # Total maximum 512MB per upload

# OCR Configuration (para "Upload as Text")
# Explicitamente excluindo Excel do OCR para usar processamento normal
ocr:
  mistralModel: 'mistral-ocr-latest'
  apiKey: '${MISTRAL_API_KEY}'
  baseURL: 'https://api.mistral.ai/v1'
  strategy: 'mistral_ocr'

# Definition of custom endpoints
endpoints:
  all:
    promptPrefix: |
      üìö Prompt de Estilo Padr√£o
      Emojis: Normalmente, use‚Äëos apenas nos cabe√ßalhos e talvez subit√≠tulos (ex.: # üöÄ T√≠tulo).
      Markdown: aplique listas, tabelas ou blocos de c√≥digo somente quando melhorar a clareza da resposta.
      Concis√£o: Sua concis√£o padr√£o, com a qual foi treinado.
      Prioridade: mem√≥rias ou prefer√™ncias do usu√°rio sempre prevalecem sobre estas instru√ß√µes.
      Fallback: se n√£o houver prefer√™ncia expl√≠cita, siga este padr√£o ou o que achar melhor para o prompt do usu√°rio.

  openAI:
    titleConvo: true
    titleModel: 'gpt-5-nano-no-reasoning'

  google:
    titleConvo: true
    titleModel: 'gemini-2.5-flash-lite'

  anthropic:
    titleConvo: true
    titleModel: 'claude-haiku-4-5'

  azureOpenAI:
    titleModel: 'gpt-5-nano-no-reasoning'
    titleConvo: true

    groups:
      # GPT-5.2 Medium
      - group: 'gpt-5.2-medium'
        apiKey: '${AZURE_API_KEY}'
        instanceName: 'ai-foundry-hpe-resource'
        deploymentName: 'gpt-5.2'
        version: '2025-01-01-preview'
        models:
          'gpt-5.2-medium': true
        addParams:
          useResponsesApi: true
          reasoning:
            effort: 'medium'
            summary: 'detailed'

      # GPT-5.2 XHigh
      - group: 'gpt-5.2-xhigh'
        apiKey: '${AZURE_API_KEY}'
        instanceName: 'ai-foundry-hpe-resource'
        deploymentName: 'gpt-5.2'
        version: '2025-01-01-preview'
        models:
          'gpt-5.2-xhigh': true
        addParams:
          useResponsesApi: true
          reasoning:
            effort: 'xhigh'
            summary: 'detailed'

      # GPT-5.2 Codex
      - group: 'gpt-5.2-codex-xhigh'
        apiKey: '${AZURE_API_KEY}'
        instanceName: 'ai-foundry-hpe-resource'
        deploymentName: 'gpt-5.2-codex'
        version: '2025-01-01-preview'
        models:
          'gpt-5.2-codex-xhigh': true
        addParams:
          useResponsesApi: true
          reasoning:
            effort: 'xhigh'
            summary: 'detailed'

  agents:
    # LibreChat Interface Creation Agents
    recursionLimit: 20
    maxRecursionLimit: 50
    disableBuilder: false
    maxCitations: 20 # Maximum total citations in responses (1-50)
    maxCitationsPerFile: 10 # Maximum citations from each file (1-10)
    capabilities:
      [
        'execute_code',
        'file_search',
        'actions',
        'tools',
        'artifacts',
        'context',
        'ocr',
        'chain',
        'web_search',
      ]

  custom:
    - name: 'OpenAI (Open Source Models)'
      apiKey: '${GROQ_API_KEY}'
      baseURL: 'https://api.groq.com/openai/v1/'
      iconURL: '/assets/openai.svg'
      addParams:
        include_reasoning: true
        reasoning_effort: 'high'
        temperature: 1.0
        top_p: 1.0
        max_completion_tokens: 32768

      models:
        default: ['openai/gpt-oss-120b', 'openai/gpt-oss-20b']
        fetch: false

      titleConvo: true
      titleModel: 'openai/gpt-oss-20b'

      tokenConfig:
        'openai/gpt-oss-120b':
          context: 131072
          prompt: 0.15
          completion: 0.75
        'openai/gpt-oss-20b':
          context: 131072
          prompt: 0.1
          completion: 0.5

    # - name: 'Meta'
    #   apiKey: '${GROQ_API_KEY}'
    #   baseURL: 'https://api.groq.com/openai/v1/'
    #   iconURL: '/assets/meta.png'
    #   addParams:
    #     temperature: 0.1
    #     top_p: 0.9
    #     frequency_penalty: 0.1
    #     presence_penalty: 0.05
    #     maxTokens: 8192
    #   models:
    #     default:
    #       [
    #         'meta-llama/llama-4-maverick-17b-128e-instruct',
    #         'meta-llama/llama-4-scout-17b-16e-instruct',
    #       ]
    #     fetch: false
    #   titleConvo: true
    #   titleModel: 'meta-llama/llama-4-maverick-17b-128e-instruct'
    #   tokenConfig:
    #     'meta-llama/llama-4-maverick-17b-128e-instruct':
    #       context: 131072
    #       prompt: 0.2
    #       completion: 0.6
    #     'meta-llama/llama-4-scout-17b-16e-instruct':
    #       context: 131072
    #       prompt: 0.11
    #       completion: 0.34

    - name: 'xai'
      apiKey: '${XAI_API_KEY}'
      baseURL: 'https://api.x.ai/v1'
      models:
        # Modelos padr√£o (pode ser ajustado conforme a necessidade)
        default:
          - 'grok-4-1-fast-reasoning' # Racioc√≠nio avan√ßado a baixo custo
          - 'grok-code-fast-1' # C√≥digo r√°pido e barato
        fetch: false # N√£o buscar modelos dinamicamente
      titleConvo: true # Usa t√≠tulo da conversa como sugest√£o de modelo
      titleModel: 'grok-4-1-fast-reasoning' # Modelo usado para gerar t√≠tulos de conversa
      modelDisplayLabel: 'Grok' # R√≥tulo gen√©rico exibido na UI
      tokenConfig:
        'grok-4-1-fast-reasoning':
          context: 2000000 # Janela de contexto de 2‚ÄØM tokens
          prompt: 0.2
          completion: 0.5
        'grok-code-fast-1':
          context: 1000000 # Janela de contexto de 256‚ÄØK tokens
          prompt: 0.2
          completion: 1.5

    # # Custom langchain Agents, google-adk Agents and openai-agents Agents
    # - name: 'HPEAgents'
    #   apiKey: 'not-required'
    #   baseURL: 'http://localhost:8073/v1'
    #   # baseURL: 'http://localhost:8000/v1'
    #   models:
    #     default: ['langchain-weather-agent', 'langchain-web-search-agent']
    #     fetch: true
    #   # Title
    #   titleConvo: false
    #   titleModel: 'langchain-weather-agent'
    #   # Token Config
    #   tokenConfig:
    #     'langchain-weather-agent':
    #       context: 8000
    #       prompt: 0.0005
    #       completion: 0.001

    # # DEEPSEEK
    # - name: 'deepseek'
    #   # Basic Info:
    #   # https://api-docs.deepseek.com/quick_start/pricing
    #   apiKey: '${DEEPSEEK_API_KEY}'
    #   baseURL: 'https://api.deepseek.com/v1'
    #   # Models:
    #   models:
    #     default: ['deepseek-chat', 'deepseek-reasoner']
    #     fetch: true
    #   # Title
    #   titleConvo: true
    #   titleModel: 'deepseek-chat'
    #   # Token Config
    #   tokenConfig:
    #     'deepseek-chat':
    #       context: 64000
    #       prompt: 0.001
    #       completion: 0.002
    #     'deepseek-reasoner':
    #       context: 64000
    #       prompt: 0.001
    #       completion: 0.002

    # # NVIDIA NIM
    # - name: 'NVIDIA'
    #   # Basic Info:
    #   # https://build.nvidia.com/
    #   apiKey: '${NVIDIA_NIM_API_KEY}'
    #   baseURL: 'https://integrate.api.nvidia.com/v1'
    #   iconURL: 'https://upload.wikimedia.org/wikipedia/sco/2/21/Nvidia_logo.svg'
    #   # Models:
    #   models:
    #     default: ['qwen/qwen3-235b-a22b', 'nvidia/llama-3.1-nemotron-ultra-253b-v1']
    #     fetch: false
    #   # Title
    #   titleConvo: true
    #   titleModel: 'qwen/qwen3-235b-a22b'
    #   # Token Config
    #   tokenConfig:
    #     'qwen/qwen3-235b-a22b': # https://build.nvidia.com/nvidia/llama-3_1-nemotron-ultra-253b-v1
    #       context: 128000
    #       prompt: 0.001
    #       completion: 0.002
    #     'nvidia/llama-3.1-nemotron-ultra-253b-v1': # https://build.nvidia.com/qwen/qwen3-235b-a22b
    #       context: 128000
    #       prompt: 0.001
    #       completion: 0.002

    # - name: 'deepseek'
    #   apiKey: '${FIREWORKS_API_KEY}'
    #   baseURL: 'https://api.fireworks.ai/inference/v1'
    #   iconURL: '/assets/deepseek.svg'
    #   addParams:
    #     temperature: 0.1
    #     top_p: 0.9
    #     frequency_penalty: 0.1
    #     presence_penalty: 0.05
    #     maxTokens: 32000
    #   models:
    #     default:
    #       ['accounts/fireworks/models/deepseek-v3p1', 'accounts/fireworks/models/gpt-oss-20b']
    #     fetch: false
    #   titleConvo: true
    #   titleModel: 'accounts/fireworks/models/gpt-oss-20b'
    #   tokenConfig:
    #     'accounts/fireworks/models/deepseek-v3p1':
    #       context: 159000
    #       prompt: 0.56
    #       completion: 1.68
    #     'accounts/fireworks/models/gpt-oss-20b':
    #       context: 131072
    #       prompt: 0.1
    #       completion: 0.5

    # - name: 'Z.ai'
    #   apiKey: '${FIREWORKS_API_KEY}'
    #   baseURL: 'https://api.fireworks.ai/inference/v1'
    #   iconURL: '/assets/zai.svg'
    #   addParams:
    #     temperature: 0.1
    #     top_p: 0.9
    #     frequency_penalty: 0.1
    #     presence_penalty: 0.05
    #     maxTokens: 32000
    #   models:
    #     default: [
    #         # GLM
    #         'accounts/fireworks/models/glm-4p5',
    #         'accounts/fireworks/models/gpt-oss-20b',
    #       ]
    #     fetch: false
    #   titleConvo: true
    #   titleModel: 'accounts/fireworks/models/gpt-oss-20b'
    #   tokenConfig:
    #     'accounts/fireworks/models/glm-4p5':
    #       context: 160000
    #       prompt: 0.55
    #       completion: 2.19
    #     'accounts/fireworks/models/gpt-oss-20b':
    #       context: 131072
    #       prompt: 0.1
    #       completion: 0.5

    # - name: 'Chutes'
    #   apiKey: '${CHUTES_API_KEY}'
    #   baseURL: 'https://llm.chutes.ai/v1'
    #   iconURL: '/assets/moonshotai.png'
    #   addParams:
    #     temperature: 0.7
    #     maxTokens: 32000
    #     reasoning_effort: 'high'
    #   models:
    #     default: [
    #         # Kimi K2
    #         'moonshotai/Kimi-K2-Thinking',
    #         'moonshotai/Kimi-K2-Instruct-0905',
    #       ]
    #     fetch: false
    #   titleConvo: false
    #   # titleModel:
    #   tokenConfig:
    #     'moonshotai/Kimi-K2-Thinking':
    #       context: 260000
    #       prompt: 0.6
    #       completion: 2.5
    #     'moonshotai/Kimi-K2-Instruct-0905':
    #       context: 260000
    #       prompt: 0.6
    #       completion: 2.5

    # - name: 'MoonshotAI'
    #   apiKey: '${FIREWORKS_API_KEY}'
    #   baseURL: 'https://api.fireworks.ai/inference/v1'
    #   iconURL: '/assets/moonshotai.png'
    #   addParams:
    #     temperature: 0.7
    #     maxTokens: 32000
    #     reasoning_effort: 'high'
    #   models:
    #     default: [
    #         # Kimi K2
    #         'accounts/fireworks/models/kimi-k2-thinking',
    #         'accounts/fireworks/models/gpt-oss-120b',
    #         'accounts/fireworks/models/gpt-oss-20b',
    #       ]
    #     fetch: false
    #   titleConvo: true
    #   titleModel: 'accounts/fireworks/models/gpt-oss-20b'
    #   tokenConfig:
    #     'accounts/fireworks/models/kimi-k2-thinking':
    #       context: 260000
    #       prompt: 0.6
    #       completion: 2.5
    #     'accounts/fireworks/models/gpt-oss-120b':
    #       context: 131072
    #       prompt: 0.15
    #       completion: 0.6
    #     'accounts/fireworks/models/gpt-oss-20b':
    #       context: 131072
    #       prompt: 0.07
    #       completion: 0.3

    # - name: 'Alibaba'
    #   apiKey: '${FIREWORKS_API_KEY}'
    #   baseURL: 'https://api.fireworks.ai/inference/v1'
    #   iconURL: '/assets/alibaba.png'
    #   addParams:
    #     temperature: 0.1
    #     top_p: 0.9
    #     frequency_penalty: 0.1
    #     presence_penalty: 0.05
    #     maxTokens: 32000
    #   models:
    #     default: [
    #         # Qwen
    #         'accounts/fireworks/models/qwen3-235b-a22b-instruct-2507',
    #         'accounts/fireworks/models/qwen3-235b-a22b-thinking-2507',
    #         'accounts/fireworks/models/qwen3-coder-480b-a35b-instruct',
    #         'accounts/fireworks/models/gpt-oss-20b',
    #       ]
    #     fetch: false
    #   titleConvo: true
    #   titleModel: 'accounts/fireworks/models/gpt-oss-20b'
    #   tokenConfig:
    #     'accounts/fireworks/models/qwen3-235b-a22b-instruct-2507':
    #       context: 128000
    #       prompt: 0.22
    #       completion: 0.88
    #     'accounts/fireworks/models/qwen3-235b-a22b-thinking-2507':
    #       context: 255000
    #       prompt: 0.22
    #       completion: 0.88
    #     'accounts/fireworks/models/qwen3-coder-480b-a35b-instruct':
    #       context: 255000
    #       prompt: 0.45
    #       completion: 1.8
    #     'accounts/fireworks/models/gpt-oss-20b':
    #       context: 131072
    #       prompt: 0.1
    #       completion: 0.5

memory:
  disabled: false
  validKeys: [
      'hpe_profile', # Quem √© o colaborador na estrutura (Nome, Cargo, √Årea, Unidade: Catal√£o/SP)
      'corporate_context', # Regras macro da HPE, Compliance, Siglas da Montadora, Pol√≠ticas
      'dept_business_rules', # Regras espec√≠ficas da √°rea (Industrial, Jur√≠dico, P√≥s-Venda, Mkt)
      'comm_style_email', # Estilos de E-mail (Formal, Interno, Fornecedores, Assinaturas)
      'workflow_tools', # Ferramentas de trabalho (SAP, Salesforce, Python, Excel, Jira)
      'active_priorities', # O que √© urgente agora para este colaborador
    ]
  tokenLimit: 4000
  personalize: true
  messageWindowSize: 10
  agent:
    provider: 'xai'
    model: 'grok-4-1-fast-reasoning'

    instructions: |
      You are the Official Enterprise Memory System for HPE Automotores do Brasil (Mitsubishi Motors).
      Your primary mandate is to ensure business continuity, professional consistency, and alignment with company standards across ALL departments.

      ## üè¢ HIERARCHY OF IMPORTANCE (STRICT ORDER):

      ### 1. üè≠ THE AUTOMAKER (HPE/MITSUBISHI) COMES FIRST
      - Prioritize information that affects the company's integrity or operations.
      - Store terminology specific to the automotive industry (e.g., CKD, SKD, PDI, Recall, Warranty).
      - If a user defines a "Company Policy" or "Standard Procedure", this is the highest priority memory.

      ### 2. üìß COMMUNICATION & EMAIL STANDARDS (HIGH PRIORITY)
      - **Crucial:** Capture the user's specific voice for emails.
      - Differentiate contexts:
        - *Internal (Peers):* Casual/Direct?
        - *Executive (Upward):* Concise, KPI-focused?
        - *External (Suppliers/Dealers):* Formal, Documented?
      - Store signature preferences and greetings.

      ### 3. üìÇ DEPARTMENTAL CONTEXT (DOMAIN AGNOSTIC)
      - Identify the department immediately and adapt storage logic:
        - **Industrial/Production:** Store Shift times, Line metrics, Safety (CIPA/SESMT) rules.
        - **Commercial/Sales:** Store Dealer codes, Region definitions, Sales targets.
        - **Finance/Fiscal:** Store Tax codes, Cost Centers, Approval limits.
        - **Legal:** Store Clause preferences, Contract types, Deadlines.
        - **IT/Tech:** (Only here) Store Stacks, Architecture, Deploy rules.

      ### 4. üõ†Ô∏è TOOLS & PREFERENCES (OPERATIONAL)
      - Only after understanding the business context, store the *how*.
      - Examples: "User prefers Excel for Finance", "User uses Python for Data", "User uses SAP T-Codes".

      ## üß† STORAGE TRIGGER EXAMPLES:

      #### ‚úÖ SAVE (Permanent Business Value):
      - "In emails to MMC Japan, always use very formal English and apologize for delays." -> `comm_style_email`
      - "The Catal√£o plant shuts down for maintenance in July." -> `corporate_context`
      - "For Warranty claims, we only accept photos in JPG format." -> `dept_business_rules`
      - "My job title is Dealer Network Manager." -> `hpe_profile`

      #### ‚ùå DO NOT SAVE (Transient/Sensitive):
      - "Draft an email for John about lunch." (Too casual)
      - "Here is the password for the SAP user." (SECURITY VIOLATION - IGNORE)
      - "Use a blue background for this specific chart." (One-off formatting)

      ## ‚ö†Ô∏è SAFETY & COMPLIANCE:
      - strictly ignore PII (CPF, RG) and Sensitive Financial Data (Credit Card, Raw Bank Info).
      - Maintain professional distance. This is a work tool.

    model_parameters:
      reasoning_effort: 'medium'
      temperature: 0.15 # Baixa para manter o tom corporativo e evitar inven√ß√µes.
      max_tokens: 1500

webSearch:
  # Search Provider Configuration
  serperApiKey: '${SERPER_API_KEY}' # ‚úÖ Correct: Using environment variable name
  # serperApiKey: "sk-123..."               # ‚ùå Wrong: Never put actual API keys here

  # Scraper Configuration
  firecrawlApiKey: '${FIRECRAWL_API_KEY}'
  # firecrawlApiKey: "fc-123..."            # ‚ùå Wrong: Never put actual API keys here

  # Reranker Configuration
  jinaApiKey: '${JINA_API_KEY}'

  searchProvider: 'serper' # Only use Serper for search
  scraperType: 'firecrawl' # Only use Firecrawl for scraping
  rerankerType: 'jina' # Only use Jina for reranking

