{
  "chatgpt-4o-latest": {
    "title": "ChatGPT-4o (Omni, Latest)",
    "description": "Modelo nativamente multimodal (texto + imagem + áudio) que responde em ~300 ms, entrega raciocínio nível GPT-4 com metade do custo e 5× mais chamadas por minuto. Licenciado para uso comercial via OpenAI API.",
    "image": "/assets/openai-logo.jpg",
    "useCases": [
      "Assistentes de voz em tempo real",
      "Chats multimodais com upload de imagem/voz",
      "Tradução instantânea e interpretação simultânea",
      "Ferramentas interativas de programação e depuração"
    ],
    "characteristics": {
      "reasoning": true,
      "speed": "fast",
      "intelligence": "very-high",
      "coding": true,
      "math": true,
      "multimodal": true
    }
  },

  "o3-2025-04-16": {
    "title": "OpenAI o3",
    "description": "Novo topo de linha em raciocínio: estabelece SOTA em Codeforces e MMMU, analisa imagens, gráficos e problemas multi-passo. Janela de 256 k tokens e forte desempenho em ciência, código e matemática.",
    "image": "/assets/openai-logo.jpg",
    "useCases": [
      "Análises científicas com dados visuais",
      "Depuração e refatoração de bases de código complexas",
      "Explicação de gráficos e diagramas técnicos",
      "Assistentes corporativos para decisões multi-fator"
    ],
    "characteristics": {
      "reasoning": true,
      "speed": "medium",
      "intelligence": "very-high",
      "coding": true,
      "math": true,
      "multimodal": true
    }
  },

  "o4-mini-2025-04-16": {
    "title": "OpenAI o4-Mini",
    "description": "Versão compacta da série o4: 4× menos custo que o o3, latência baixa e foco em diálogo e síntese; janela de 128 k tokens em uma única GPU.",
    "image": "/assets/openai-logo.jpg",
    "useCases": [
      "Chatbots de alta inteligência em tempo real",
      "Sumarização de documentos extensos",
      "Raciocínio embarcado em apps móveis",
      "Protótipos RAG rápidos e econômicos"
    ],
    "characteristics": {
      "reasoning": true,
      "speed": "fast",
      "intelligence": "high",
      "coding": true,
      "math": true,
      "multimodal": false
    }
  },

  "gpt-4.1-2025-04-14": {
    "title": "GPT-4.1",
    "description": "Família de uso geral com janela de até 1 M tokens, +21 % de ganho em código versus GPT-4o e custo reduzido. Atualizada até jun/2024 e focada em instruções longas e agentes RAG.",
    "image": "/assets/openai-logo.jpg",
    "useCases": [
      "Processamento e consulta de documentos gigantes",
      "Geração e auditoria de código avançado",
      "Pipelines de RAG corporativos",
      "Assistentes empresariais com contexto profundo"
    ],
    "characteristics": {
      "reasoning": true,
      "speed": "medium",
      "intelligence": "very-high",
      "coding": true,
      "math": true,
      "multimodal": false
    }
  },

  "gpt-4.1-mini-2025-04-14": {
    "title": "GPT-4.1 Mini",
    "description": "Redução de custo e latência da série 4.1 — janela 512 k, desempenho de código próximo ao GPT-4 clássico em apenas uma GPU A100.",
    "image": "/assets/openai-logo.jpg",
    "useCases": [
      "IDE assistants com contexto grande",
      "Relatórios executivos gerados sob demanda",
      "Chat apps SaaS com longas threads",
      "Integração de agentes em micro-serviços"
    ],
    "characteristics": {
      "reasoning": true,
      "speed": "fast",
      "intelligence": "high",
      "coding": true,
      "math": true,
      "multimodal": false
    }
  },

  "gpt-4.1-nano-2025-04-14": {
    "title": "GPT-4.1 Nano",
    "description": "Primeiro modelo nano da OpenAI — cabe em laptop moderno ou edge GPU, janela 128 k e resposta quase instantânea; ideal para apps offline ou IoT.",
    "image": "/assets/openai-logo.jpg",
    "useCases": [
      "Assistentes on-device sem conexão",
      "Tradução local em tempo real",
      "Chatbots embarcados em dispositivos IoT",
      "Fine-tuning leve para domínios específicos"
    ],
    "characteristics": {
      "reasoning": true,
      "speed": "fast",
      "intelligence": "medium",
      "coding": true,
      "math": true,
      "multimodal": false
    }
  },

  "deepseek-ai/deepseek-r1": {
    "title": "DeepSeek R1",
    "description": "Modelo de 671 B parâmetros totais (37 B ativos) treinado quase só com reforço por aprendizado, resultando em cadeias de raciocínio longas, auto-verificação natural e desempenho no nível do OpenAI o1 em matemática, código e lógica — tudo com licença MIT e custo de treino extraordinariamente baixo.",
    "image": "/assets/deepseek-logo.jpg",
    "useCases": [
      "Provas de matemática de alto nível (AIME, MATH-500)",
      "Programação competitiva e depuração complexa",
      "Pesquisa científica que exija raciocínio passo a passo",
      "Distilação para modelos menores mantendo o padrão de raciocínio"
    ],
    "characteristics": {
      "reasoning": true,
      "speed": "medium",
      "intelligence": "high",
      "coding": true,
      "math": true,
      "multimodal": false
    }
  },

  "meta/llama-4-maverick-17b-128e-instruct": {
    "title": "Llama 4 Maverick 17B-128E",
    "description": "Versão de alta potência da série Llama 4: 17 B parâmetros ativados de um total de ~400 B distribuídos por 128 especialistas, janela de 128 k tokens e suporte nativo a texto+imagem. Indicada para geração de código complexa e aplicações multimodais exigentes com licença Llama 4 Community.",
    "image": "/assets/meta-llama-logo.webp",
    "useCases": [
      "Agentes multimodais que chamam ferramentas externas",
      "Geração e revisão de código em larga escala",
      "Criação de conteúdos ricos (texto + imagem)",
      "Pipelines de RAG com contexto muito extenso"
    ],
    "characteristics": {
      "reasoning": true,
      "speed": "fast",
      "intelligence": "high",
      "coding": true,
      "math": true,
      "multimodal": false
    }
  },

  "meta/llama-4-scout-17b-16e-instruct": {
    "title": "Llama 4 Scout 17B-16E",
    "description": "Modelo enxuto (17 B ativos / 109 B totais, 16 especialistas) pensado para servir chats multimodais em uma única GPU H100, trazendo janela de até 10 M tokens via RoPE e ótima relação custo-latência.",
    "image": "/assets/meta-llama-logo.webp",
    "useCases": [
      "Chatbots multimodais de alta velocidade",
      "Aplicações móveis ou edge com GPU única",
      "Protótipos rápidos de IA conversacional",
      "Experimentos de fine-tuning leve (custo acessível)"
    ],
    "characteristics": {
      "reasoning": true,
      "speed": "fast",
      "intelligence": "high",
      "coding": true,
      "math": true,
      "multimodal": false
    }
  },

  "nvidia/llama-3.1-nemotron-ultra-253b-v1": {
    "title": "Llama 3.1 Nemotron Ultra 253B-v1",
    "description": "Gigante de 253 B parâmetros denso, derivado do Llama-3.1-405B, otimizado via NAS para encaixar em um nó 8×H100 mantendo janela de 128 k tokens. Afinado para agentes, RAG e chamadas de ferramenta, com forte score em lógica, código e matemática.",
    "image": "/assets/nvidia-nemotron-logo.webp",
    "useCases": [
      "Assistentes corporativos que integram APIs",
      "Chatbots multilíngues com contexto extenso",
      "Sistemas de RAG e análise documental",
      "Pesquisa científica computacional pesada"
    ],
    "characteristics": {
      "reasoning": true,
      "speed": "slow",
      "intelligence": "very-high",
      "coding": true,
      "math": true,
      "multimodal": false
    }
  },

  "qwen/qwen3-235b-a22b": {
    "title": "Qwen 3-235B-A22B",
    "description": "MoE com 235 B totais (22 B ativos) que alterna entre modo \"thinking\" para problemas difíceis e modo rápido para diálogo, suporta 100+ idiomas, janela nativa 32 k (até 131 k via YaRN) e licença Apache 2.0.",
    "image": "/assets/alibaba-qwen-logo.jpg",
    "useCases": [
      "Plataformas globais de atendimento multicanal",
      "Tradução e localização de grande volume",
      "Geração de conteúdo intercultural",
      "Agentes conversacionais com raciocínio profundo"
    ],
    "characteristics": {
      "reasoning": true,
      "speed": "medium",
      "intelligence": "high",
      "coding": true,
      "math": true,
      "multimodal": true
    }
  },

  "qwen3-235b-a22b": {
    "title": "Qwen 3-235B-A22B",
    "description": "MoE com 235 B totais (22 B ativos) que alterna entre modo \"thinking\" para problemas difíceis e modo rápido para diálogo, suporta 100+ idiomas, janela nativa 32 k (até 131 k via YaRN) e licença Apache 2.0.",
    "image": "/assets/alibaba-qwen-logo.jpg",
    "useCases": [
      "Plataformas globais de atendimento multicanal",
      "Tradução e localização de grande volume",
      "Geração de conteúdo intercultural",
      "Agentes conversacionais com raciocínio profundo"
    ],
    "characteristics": {
      "reasoning": true,
      "speed": "medium",
      "intelligence": "high",
      "coding": true,
      "math": true,
      "multimodal": true
    }
  },

  "qwen3-32b": {
    "title": "Qwen 3-32B",
    "description": "Modelo denso de 32,8 B parâmetros, janela 32 k (até 131 k via YaRN) e suporte a 119 idiomas; oferece desempenho próximo a modelos de 70 B da geração anterior com menor custo e latência.",
    "image": "/assets/alibaba-qwen-logo.jpg",
    "useCases": [
      "Deploy SaaS multilíngue em nuvem",
      "Geração de relatórios e sumários longos",
      "Assistentes de programação com contexto extenso",
      "Aplicações de análise de documentos"
    ],
    "characteristics": {
      "reasoning": true,
      "speed": "medium",
      "intelligence": "high",
      "coding": true,
      "math": true,
      "multimodal": true
    }
  },

  "qwen3-4b": {
    "title": "Qwen 3-4B",
    "description": "Versão compacta (4,0 B parâmetros) que cabe em GPU simples, mantendo janela de 32 k tokens e suporte a 100+ idiomas – excelente para aplicações locais, mobile ou edge que exijam tradução e chat rápidos.",
    "image": "/assets/alibaba-qwen-logo.jpg",
    "useCases": [
      "Apps móveis de tradução em tempo real",
      "Chatbots embarcados em dispositivos IoT",
      "Assistentes pessoais off-line",
      "Fine-tuning leve para domínios específicos"
    ],
    "characteristics": {
      "reasoning": true,
      "speed": "medium",
      "intelligence": "high",
      "coding": true,
      "math": true,
      "multimodal": true
    }
  }
}
